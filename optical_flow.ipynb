{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Create 3 versions of a video with slow motion effects using interpolation of frames. The three versions are:\n",
    "\n",
    "Repeat: frames interpolated by repetition of the original frame\\\n",
    "$fr_{new} = fr_{prev}$\n",
    "\n",
    "Linear: frames interpolated linearly\\\n",
    "$fr_{new} = t \\cdot fr_{prev} + (1 - t) \\cdot fr_{next}$\n",
    "\n",
    "Optical Flow: frames interpolated using optical flow\\\n",
    "$fr_{new} = t \\cdot fr_{flow} + (1 - t) \\cdot fr_{next}$\n",
    "\n",
    "The optical flow can be calculated using the Horn-Schunck method or the Farneback method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'assets/onca.mp4'\n",
    "\n",
    "# 8 frames to be inserted between each pair of consecutive frames from the original video\n",
    "fator = 8 \n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output video\n",
    "\n",
    "# interpolation by repetition\n",
    "outrep_width = width\n",
    "outrep_height = height\n",
    "\n",
    "# linear interpolation\n",
    "outlin_width = width\n",
    "outlin_height = height\n",
    "\n",
    "# opt flow interpolation\n",
    "outopt_width = width\n",
    "outopt_height = height\n",
    "\n",
    "# video with all three for comparison\n",
    "outcomb_width = 3*width \n",
    "outcomb_height = height\n",
    "\n",
    "# Create object VideoWriter to save the videos\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "outrep_path = 'output/out_rep.mp4'\n",
    "outlin_path = 'output/out_lin.mp4'\n",
    "outopt_path = 'output/out_opt.mp4'\n",
    "outcomb_path = 'output/out_comb.mp4'\n",
    "\n",
    "outrep = cv2.VideoWriter(outrep_path, fourcc, fps, (outrep_width, outrep_height))\n",
    "outlin = cv2.VideoWriter(outlin_path, fourcc, fps, (outlin_width, outlin_height))\n",
    "outopt = cv2.VideoWriter(outopt_path, fourcc, fps, (outopt_width, outopt_height))\n",
    "outcomb = cv2.VideoWriter(outcomb_path, fourcc, fps, (outcomb_width, outcomb_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to insert interpolated frames\n",
    "def combine_frames(frames):\n",
    "    height = frames[0][0].shape[0]\n",
    "    width = frames[0][0].shape[1]\n",
    "    channels = frames[0][0].shape[2]\n",
    "    combined_frame = np.zeros((height, width * len(frames), channels), dtype=np.uint8)\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        combined_frame[:, i * width : (i + 1) * width, :] = frame[0]\n",
    "\n",
    "    return combined_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  10 %\n",
      "Processing:  20 %\n",
      "Processing:  30 %\n",
      "Processing:  40 %\n",
      "Processing:  50 %\n",
      "Processing:  60 %\n",
      "Processing:  70 %\n",
      "Processing:  80 %\n",
      "Processing:  90 %\n",
      "Processing:  100 %\n"
     ]
    }
   ],
   "source": [
    "# coordinate map for optical flow\n",
    "coord_x, coord_y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "frames_count = 0; total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT); block = int(total_frames/10)\n",
    "\n",
    "# bring the video back to the beginning\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "ret, prev_frame = cap.read()\n",
    "while cap.isOpened():\n",
    "    frames_count += 1\n",
    "\n",
    "    # print progress\n",
    "    if frames_count % block == 0:\n",
    "        print('Processing: ', int(frames_count/block)*10, '%')\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # start with the previous frame\n",
    "    frame_repeat = cv2.resize(prev_frame, (outrep_width, outrep_height))\n",
    "    frame_linear = cv2.resize(prev_frame, (outlin_width, outlin_height))\n",
    "    frame_optflow = cv2.resize(prev_frame, (outopt_width, outopt_height))\n",
    "\n",
    "    frame_combinado = combine_frames([[frame_repeat], [frame_linear], [frame_optflow]])\n",
    "    frame_combinado = cv2.resize(frame_combinado, (outcomb_width, outcomb_height))\n",
    "\n",
    "    # write each frame to the corresponding output video\n",
    "    outrep.write(frame_repeat)\n",
    "    outlin.write(frame_linear)\n",
    "    outopt.write(frame_optflow)\n",
    "    outcomb.write(frame_combinado)\n",
    "    \n",
    "    # optical flow\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow using the Farneback method already implemented by OpenCV\n",
    "    # the method parameters are:\n",
    "    # prev_gray: previous frame in grayscale\n",
    "    # gray: current frame in grayscale\n",
    "    # None: no mask\n",
    "    # 0.5: scale pyramid, scale factor\n",
    "    # 3: number of pyramid levels\n",
    "    # 15: size of the window neighborhood\n",
    "    # 3: number of iterations of the algorithm\n",
    "    # 5: size of the averaging window for smoothing\n",
    "    # 1.2: standard deviation of the Gaussian filter\n",
    "    # 0: flags\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # insert intermediate frames\n",
    "    for i in range(1, fator):\n",
    "        # interpolation by repetition\n",
    "        frame_repeat = prev_frame\n",
    "\n",
    "        # linear interpolation\n",
    "        frame_linear = cv2.addWeighted(prev_frame, (fator - i) / fator, frame, i / fator, 0)\n",
    "\n",
    "        # optical flow interpolation\n",
    "        # we modify the x and y coordinates according to the optical flow\n",
    "        # the map map_x contains the x coordinates of each pixel of the current frame\n",
    "        # it must be calculated from the original x coordinate map (coord_x) and the optical flow\n",
    "        map_x = coord_x - flow[:, :, 0] * i / fator\n",
    "        map_y = coord_y - flow[:, :, 1] * i / fator\n",
    "        frame_optflow = cv2.remap(prev_frame, map_x.astype(np.float32), map_y.astype(np.float32), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # finally, interpolate linearly between the next frame and the transformed one\n",
    "        peso_fluxo_otico = 1 - i / fator\n",
    "        peso_proximo_frame = i / fator\n",
    "        frame_optflow = cv2.addWeighted(frame_optflow, peso_fluxo_otico, frame, peso_proximo_frame, 0)\n",
    "\n",
    "        frame_combinado = combine_frames([[frame_repeat], [frame_linear], [frame_optflow]])\n",
    "        \n",
    "        outrep.write(frame_repeat)\n",
    "        outlin.write(frame_linear)\n",
    "        outopt.write(frame_optflow)\n",
    "        outcomb.write(frame_combinado)\n",
    "\n",
    "    prev_frame = frame\n",
    "\n",
    "cap.release()\n",
    "outrep.release()\n",
    "outlin.release()\n",
    "outopt.release()\n",
    "outcomb.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2) Describe briefly the results you found in item (1). Which method is better? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While in linear interpolation we apply a simple weighted average between the frames of the video, the strategy in optical flow is to calculate the instantaneous speed of the objects in a frame and produce intermediate frames faithful to that speed. This makes the result smoother and closer to what the original video would be in slow motion.\\\n",
    "\\\n",
    "The sensorial effect of linear interpolation is that of a slower and more dragged video, with a \"ghost\" effect on moving objects, almost as if the spectator were drunk.\\\n",
    "On the other hand, the sensorial effect of optical flow is that of a smoother video, with more natural movements and that minimizes the \"ghost\" effect on moving objects.\\\n",
    "Finally, repeating the frames only makes the video slower, without any interesting sensorial effect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
